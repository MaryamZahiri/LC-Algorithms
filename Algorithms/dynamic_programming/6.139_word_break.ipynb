{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "139. [Word Break](https://leetcode.com/problems/word-break/description/)\n",
    "\n",
    "Given a string s and a dictionary of strings wordDict, return true if s can be segmented into a space-separated sequence of one or more dictionary words.\n",
    "\n",
    "Note that the same word in the dictionary may be reused multiple times in the segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Down Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "class Solution:\n",
    "    def wordBreak(self, s: str, wordDict) -> bool:\n",
    "        @cache\n",
    "        def dfs(i):\n",
    "            dp = [False] * (len(s) + 1)\n",
    "            if i == len(s): return True \n",
    "            for w in wordDict:\n",
    "                if (i + len(w)) <= len(s) and s[i:i+len(w)] == w:\n",
    "                    if dfs(i + len(w)):\n",
    "                        return dfs(i + len(w))\n",
    "                    else: dp[i + len(w)] = True\n",
    "            else: return False\n",
    "        return dfs(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@cache is a decorator provided by the functools module. It's used to memoize function calls, which means it stores the results of expensive function calls and returns the cached result when the same inputs occur again.\n",
    "\n",
    "Here's a breakdown of how it works:\n",
    "\n",
    "1. The @cache decorator is applied above the dfs function definition.\n",
    "\n",
    "2. When dfs is called with a particular argument i, it checks if the result for that i is already stored in its cache.\n",
    "\n",
    "3. If the result is found in the cache, it returns the cached result without recomputing.\n",
    "\n",
    "4. If the result isn't in the cache, it computes the result normally and then stores it in the cache for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Complexity: O(n*m)\n",
    "- Without caching, this could lead to exponential time complexity.\n",
    "By memoizing intermediate results, we reduce the time complexity to O(n * m), where n is the length of the string and m is the number of words in the dictionary.\n",
    "\n",
    "Space Complexity: O(n)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
